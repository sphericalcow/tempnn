{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainval / test\n",
    "\n",
    "\n",
    "jumping, other, phoning, playinginstrument, reading, ridingbike, ridinghorse, running, takingphoto, usingcomputer, walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import cv2\n",
    "import caffe\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.svm\n",
    "import sklearn.linear_model\n",
    "import sklearn.kernel_approximation # RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), 'datasets/pascal/'))\n",
    "import pascal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESNET_PATH = '/home/omer/MyRoot/work/grideas/pretrained/resnet152'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images, classnames, poses = pascal.annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()\n",
    "resnet = caffe.Net(os.path.join(RESNET_PATH, 'ResNet-152-deploy.prototxt'), caffe.TEST)\n",
    "resnet.copy_from(os.path.join(RESNET_PATH, 'ResNet-152-model.caffemodel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_name = images.keys()[np.random.randint(len(images.keys()))]\n",
    "img = cv2.cvtColor(cv2.imread(pascal.imagefile(img_name), cv2.IMREAD_COLOR), cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "offset = lambda dim, size: int(np.floor((dim-size)*0.5))\n",
    "sizeX, sizeY = 224, 224\n",
    "offsetY, offsetX = offset(img.shape[0], sizeY), offset(img.shape[1], sizeX)\n",
    "cropped = img[offsetY:offsetY+sizeY, offsetX:offsetX+sizeX, :].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(cropped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_input = np.zeros((1, 3, 224, 224))\n",
    "cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "for c in xrange(cropped.shape[2]):\n",
    "    im_input[0, c :, :] = cropped[:, :, c]\n",
    "resnet.blobs['data'].data[...] = im_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# result = resent.forward(end='res5a')\n",
    "result = resnet.forward(start='conv1')\n",
    "# /esult = resnet.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.argmax(result['prob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And... TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet_load(resnet_path=RESNET_PATH):\n",
    "    caffe.set_mode_cpu()\n",
    "    resnet = caffe.Net(os.path.join(resnet_path, 'ResNet-152-deploy.prototxt'), caffe.TEST)\n",
    "    resnet.copy_from(os.path.join(resnet_path, 'ResNet-152-model.caffemodel'))    \n",
    "    return resnet\n",
    "\n",
    "def resnet_crop(img):\n",
    "    offset = lambda dim, size: int(np.floor((dim-size)*0.5))\n",
    "    sizeX, sizeY = 224, 224\n",
    "    offsetY, offsetX = offset(img.shape[0], sizeY), offset(img.shape[1], sizeX)\n",
    "    cropped = img[offsetY:offsetY+sizeY, offsetX:offsetX+sizeX, :].squeeze()\n",
    "    return cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def resnet_setinputs(resnet_model, data):\n",
    "    im_input = np.zeros((1, 3, 224, 224))\n",
    "    for c in xrange(data.shape[2]):\n",
    "        im_input[0, c :, :] = data[:, :, c]\n",
    "    resnet_model.blobs['data'].data[...] = im_input\n",
    "    return resnet_model\n",
    "\n",
    "def get_image(images, image_name=None):\n",
    "    if image_name is None:\n",
    "        image_name = images.keys()[np.random.randint(len(images.keys()))]\n",
    "    return cv2.cvtColor(cv2.imread(pascal.imagefile(image_name), cv2.IMREAD_COLOR), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def get_features(image, caffe_model, blob_name):\n",
    "    resnet_model = resnet_setinputs(caffe_model, resnet_crop(image))\n",
    "    return resnet.forward(end=blob_name)[blob_name][0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "Xlst = []\n",
    "Ylst = []\n",
    "\n",
    "for imgname, info in images.items():\n",
    "    Xlst.append(imgname)\n",
    "    Ylst.append('person' in [curr_obj['classname'] for curr_obj in info['objects']])\n",
    "    counter += 1\n",
    "    if counter > 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm = sklearn.linear_model.SGDClassifier(loss='hinge')\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "for idx in xrange(BATCH_SIZE):\n",
    "    print idx, Xlst[idx]\n",
    "    features = get_features(get_image(images, Xlst[idx]), resnet, 'res5a')\n",
    "    print features.shape\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for nm in Xlst:\n",
    "    get_image(images, nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet = resnet_load(RESNET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = get_features(get_image(images), resnet, 'res5a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# svm = sklearn.svm.SVC(C=1.0, kernel='rbf')\n",
    "# SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
